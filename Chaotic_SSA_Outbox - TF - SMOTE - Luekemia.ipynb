{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8797861",
   "metadata": {},
   "source": [
    "#### First we start by importing all relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca7f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from numpy.random import rand\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, f_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "random_state = 42\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6937325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V3563</th>\n",
       "      <th>V3564</th>\n",
       "      <th>V3565</th>\n",
       "      <th>V3566</th>\n",
       "      <th>V3567</th>\n",
       "      <th>V3568</th>\n",
       "      <th>V3569</th>\n",
       "      <th>V3570</th>\n",
       "      <th>V3571</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.788350</td>\n",
       "      <td>-0.756913</td>\n",
       "      <td>-1.414095</td>\n",
       "      <td>-0.718028</td>\n",
       "      <td>0.473398</td>\n",
       "      <td>3.113805</td>\n",
       "      <td>2.749407</td>\n",
       "      <td>2.628862</td>\n",
       "      <td>3.146849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660664</td>\n",
       "      <td>-0.277515</td>\n",
       "      <td>-0.190609</td>\n",
       "      <td>1.096830</td>\n",
       "      <td>0.069212</td>\n",
       "      <td>-0.178846</td>\n",
       "      <td>0.468823</td>\n",
       "      <td>-0.331179</td>\n",
       "      <td>-0.825661</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>-1.205542</td>\n",
       "      <td>-0.055226</td>\n",
       "      <td>0.251215</td>\n",
       "      <td>-1.213103</td>\n",
       "      <td>1.040300</td>\n",
       "      <td>3.097184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756412</td>\n",
       "      <td>-0.670722</td>\n",
       "      <td>-0.603962</td>\n",
       "      <td>0.263903</td>\n",
       "      <td>0.520380</td>\n",
       "      <td>-0.037259</td>\n",
       "      <td>0.461020</td>\n",
       "      <td>-0.390380</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.423499</td>\n",
       "      <td>-1.423499</td>\n",
       "      <td>-1.389461</td>\n",
       "      <td>-0.069438</td>\n",
       "      <td>0.911507</td>\n",
       "      <td>2.080529</td>\n",
       "      <td>1.603549</td>\n",
       "      <td>1.702697</td>\n",
       "      <td>2.980989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487601</td>\n",
       "      <td>-0.091597</td>\n",
       "      <td>0.289707</td>\n",
       "      <td>0.328599</td>\n",
       "      <td>0.732303</td>\n",
       "      <td>-0.973264</td>\n",
       "      <td>0.686988</td>\n",
       "      <td>0.355827</td>\n",
       "      <td>-0.708238</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.941616</td>\n",
       "      <td>-1.362703</td>\n",
       "      <td>-1.362703</td>\n",
       "      <td>-0.959263</td>\n",
       "      <td>-0.052647</td>\n",
       "      <td>2.210509</td>\n",
       "      <td>1.520901</td>\n",
       "      <td>1.625528</td>\n",
       "      <td>3.244964</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135454</td>\n",
       "      <td>-0.230745</td>\n",
       "      <td>-0.330132</td>\n",
       "      <td>0.483504</td>\n",
       "      <td>0.590966</td>\n",
       "      <td>-0.852819</td>\n",
       "      <td>0.327239</td>\n",
       "      <td>-0.874228</td>\n",
       "      <td>-1.149951</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 3573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   samples        V1        V2        V3        V4        V5        V6  \\\n",
       "0        1 -0.788350 -0.756913 -1.414095 -0.718028  0.473398  3.113805   \n",
       "1        2 -1.335163 -1.335163 -1.335163 -1.205542 -0.055226  0.251215   \n",
       "2        3 -1.423499 -1.423499 -1.389461 -0.069438  0.911507  2.080529   \n",
       "3        4 -0.941616 -1.362703 -1.362703 -0.959263 -0.052647  2.210509   \n",
       "\n",
       "         V7        V8        V9  ...     V3563     V3564     V3565     V3566  \\\n",
       "0  2.749407  2.628862  3.146849  ... -0.660664 -0.277515 -0.190609  1.096830   \n",
       "1 -1.213103  1.040300  3.097184  ... -0.756412 -0.670722 -0.603962  0.263903   \n",
       "2  1.603549  1.702697  2.980989  ... -0.487601 -0.091597  0.289707  0.328599   \n",
       "3  1.520901  1.625528  3.244964  ... -1.135454 -0.230745 -0.330132  0.483504   \n",
       "\n",
       "      V3567     V3568     V3569     V3570     V3571  Response  \n",
       "0  0.069212 -0.178846  0.468823 -0.331179 -0.825661    normal  \n",
       "1  0.520380 -0.037259  0.461020 -0.390380 -1.335163    normal  \n",
       "2  0.732303 -0.973264  0.686988  0.355827 -0.708238    normal  \n",
       "3  0.590966 -0.852819  0.327239 -0.874228 -1.149951    normal  \n",
       "\n",
       "[4 rows x 3573 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normally we have to import the dataset\n",
    "data_url = 'Datasets/leukemia_cancer.csv'\n",
    "data = pd.read_csv(data_url)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581eb0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V3563</th>\n",
       "      <th>V3564</th>\n",
       "      <th>V3565</th>\n",
       "      <th>V3566</th>\n",
       "      <th>V3567</th>\n",
       "      <th>V3568</th>\n",
       "      <th>V3569</th>\n",
       "      <th>V3570</th>\n",
       "      <th>V3571</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788350</td>\n",
       "      <td>-0.756913</td>\n",
       "      <td>-1.414095</td>\n",
       "      <td>-0.718028</td>\n",
       "      <td>0.473398</td>\n",
       "      <td>3.113805</td>\n",
       "      <td>2.749407</td>\n",
       "      <td>2.628862</td>\n",
       "      <td>3.146849</td>\n",
       "      <td>2.870575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660664</td>\n",
       "      <td>-0.277515</td>\n",
       "      <td>-0.190609</td>\n",
       "      <td>1.096830</td>\n",
       "      <td>0.069212</td>\n",
       "      <td>-0.178846</td>\n",
       "      <td>0.468823</td>\n",
       "      <td>-0.331179</td>\n",
       "      <td>-0.825661</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.335163</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>-1.205542</td>\n",
       "      <td>-0.055226</td>\n",
       "      <td>0.251215</td>\n",
       "      <td>-1.213103</td>\n",
       "      <td>1.040300</td>\n",
       "      <td>3.097184</td>\n",
       "      <td>2.953193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756412</td>\n",
       "      <td>-0.670722</td>\n",
       "      <td>-0.603962</td>\n",
       "      <td>0.263903</td>\n",
       "      <td>0.520380</td>\n",
       "      <td>-0.037259</td>\n",
       "      <td>0.461020</td>\n",
       "      <td>-0.390380</td>\n",
       "      <td>-1.335163</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.423499</td>\n",
       "      <td>-1.423499</td>\n",
       "      <td>-1.389461</td>\n",
       "      <td>-0.069438</td>\n",
       "      <td>0.911507</td>\n",
       "      <td>2.080529</td>\n",
       "      <td>1.603549</td>\n",
       "      <td>1.702697</td>\n",
       "      <td>2.980989</td>\n",
       "      <td>2.980989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487601</td>\n",
       "      <td>-0.091597</td>\n",
       "      <td>0.289707</td>\n",
       "      <td>0.328599</td>\n",
       "      <td>0.732303</td>\n",
       "      <td>-0.973264</td>\n",
       "      <td>0.686988</td>\n",
       "      <td>0.355827</td>\n",
       "      <td>-0.708238</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 3572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.788350 -0.756913 -1.414095 -0.718028  0.473398  3.113805  2.749407   \n",
       "1 -1.335163 -1.335163 -1.335163 -1.205542 -0.055226  0.251215 -1.213103   \n",
       "2 -1.423499 -1.423499 -1.389461 -0.069438  0.911507  2.080529  1.603549   \n",
       "\n",
       "         V8        V9       V10  ...     V3563     V3564     V3565     V3566  \\\n",
       "0  2.628862  3.146849  2.870575  ... -0.660664 -0.277515 -0.190609  1.096830   \n",
       "1  1.040300  3.097184  2.953193  ... -0.756412 -0.670722 -0.603962  0.263903   \n",
       "2  1.702697  2.980989  2.980989  ... -0.487601 -0.091597  0.289707  0.328599   \n",
       "\n",
       "      V3567     V3568     V3569     V3570     V3571  Response  \n",
       "0  0.069212 -0.178846  0.468823 -0.331179 -0.825661    normal  \n",
       "1  0.520380 -0.037259  0.461020 -0.390380 -1.335163    normal  \n",
       "2  0.732303 -0.973264  0.686988  0.355827 -0.708238    normal  \n",
       "\n",
       "[3 rows x 3572 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['samples'], axis = 1)  #dropping the sample column because its irrelevent\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00d8633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 3572)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #just to check the number of instances and features/variables our dataset have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937f2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.isnull().sum() #We check to see if our datasets has any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5517d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have two classes:  ['normal' 'tumar']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response\n",
       "normal    47\n",
       "tumar     25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check the counts of the class types in our datasets\n",
    "print(\"We have two classes: \", data['Response'].unique())\n",
    "data.value_counts('Response')\n",
    "# This tells us we have 162 instances of type cancer and 91 of type nirmal. Thus we need to do data imbalance handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7200c8",
   "metadata": {},
   "source": [
    "### We perform label encoding i.e, the target variable change from categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2759812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#machine learning algorithms cannot work with categoricla values, thus he has to label out target to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "data['Response'] = label_encoder.fit_transform(data['Response'])\n",
    "data.Response.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138e35fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47\n",
       "1    25\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Response.value_counts() #We see that the cancer class [0] is the majority class with 162 counts of samoples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01bb6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()#we make a copy of our data for future references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab29ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all elements have the same min value.\n",
      "Not all elements have the same max value.\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics to check the range of values so as to know if you need scaling\n",
    "#summary_stats = data.describe()\n",
    "#print(summary_stats)\n",
    "\n",
    "# Check the minimum and maximum values for each feature\n",
    "min_values = data.min()\n",
    "if min_values.nunique() == 0.0:\n",
    "    print(\"All elements have the same min value.\")\n",
    "else:\n",
    "    print(\"Not all elements have the same min value.\")\n",
    "\n",
    "max_values = data.max()\n",
    "if max_values.nunique() == 1.0:\n",
    "    print(\"All elements have the same max value.\")\n",
    "else:\n",
    "    print(\"Not all elements have the same max value.\")\n",
    "#from the output we need to perform a minmax scaling to make sure all our values are withing -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e2b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we split our dataframe into features and target\n",
    "features = data.drop(['Response'], axis = 1) #dropping the target column\n",
    "target = data.loc[:,['Response']] #picking only the target column\n",
    "#features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307e1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Now let us handle the imbalancenature of our dataset using ROS\n",
    "#we first haave to separate the two classes\n",
    "majority_class_cancer = data[data['Class'] == 0]\n",
    "minority_class_normal = data[data['Class'] == 1]\n",
    "\n",
    "print(\"confirming to ensure its 162 samples in the majority class cancer: \",len(majority_class_cancer.Class))\n",
    "print(\"confirming to ensure its 91 samples in the minority class cancer: \",len(minority_class_normal.Class))''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04101637",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Upsample minority class to equal majority class\n",
    "minority_upsample = resample(minority_class_normal, replace = True, n_samples = len(majority_class_cancer), random_state = random_state)\n",
    "# Combine majority class with upsampled minority class\n",
    "data_combined = pd.concat([majority_class_cancer, minority_upsample])\n",
    "print(\"Checking the shape of our data once more: \\n\", data_combined.Class.value_counts())''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e58402",
   "metadata": {},
   "source": [
    "### Now we use our SMOTE technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b169864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets use the SMOTE technique to handle the imbalance data issues\n",
    "smote = SMOTE(random_state = random_state, k_neighbors=5)\n",
    "features, target = smote.fit_resample(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d4d6553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response\n",
       "0           47\n",
       "1           47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see if SMOTE works\n",
    "target.value_counts() # These shows that the classes a rebalanced now ie., 162 both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d07dc",
   "metadata": {},
   "source": [
    "### Now we scale our data to be on same scale and avoid bais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ec0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "data_scaled = min_max_scaler.fit_transform(features)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = features.columns)\n",
    "#data_scaled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af0c92",
   "metadata": {},
   "source": [
    "### We perform filter methods of gene selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5037a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECTION WITH CHI-SQUARE TEST\n",
    "data_chi = SelectKBest(score_func = chi2)\n",
    "data_chi.fit(data_scaled, target)\n",
    "\n",
    "Table_score = pd.DataFrame(data_chi.scores_)\n",
    "Table_names = pd.DataFrame(data2.columns)\n",
    "chi_table = pd.concat([Table_names, Table_score], axis = 1)\n",
    "chi_table.columns = ['Feature_Names', 'Scores']\n",
    "chi_table.sort_values(by = 'Scores', ascending = False, inplace = True)\n",
    "#display(chi_table)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b964e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECTION WITH MUTUAL INFORMATION\n",
    "data_mi = SelectKBest(score_func = mutual_info_classif)\n",
    "target_mi = target.copy()\n",
    "#target_mi = target.ravel()\n",
    "\n",
    "target_mi = column_or_1d(target_mi)\n",
    "\n",
    "data_mi.fit(data_scaled, target_mi)\n",
    "\n",
    "Table_score = pd.DataFrame(data_mi.scores_)\n",
    "Table_names = pd.DataFrame(data2.columns)\n",
    "mi_table = pd.concat([Table_names, Table_score], axis = 1)\n",
    "mi_table.columns = ['Feature_Names', 'Scores']\n",
    "mi_table.sort_values(by = 'Scores', ascending = False, inplace = True)\n",
    "#display(mi_table)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f999006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now from our methodology, we aim to use 100, 200, 300, 400, and 500 features where the KNN will\n",
    "automnatically select the feature subset with lesser error before paissing to the SSA'''\n",
    "#we will roughly select 1000 top features from each of the filter methods\n",
    "Top_1000_chi = chi_table.head(1000)\n",
    "Top_1000_mi = mi_table.head(1000)\n",
    "\n",
    "#Now we merge the two top 1000 features from each filter method to remove duplicates. The scoring is again done automatically.\n",
    "merged_table = pd.concat([Top_1000_chi, Top_1000_mi], axis = 0)\n",
    "merged_table.shape\n",
    "#display(merged_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43ae217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we again ensure the features are ranked based on scores\n",
    "merged_table.sort_values(by = 'Scores', ascending = False, inplace = True)\n",
    "#display(merged_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e9f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any rows have the same value in the specified column\n",
    "duplicate_values = merged_table.duplicated(subset=['Feature_Names'], keep=False)\n",
    "# Filter the DataFrame to show only the rows with duplicate values\n",
    "rows_with_duplicates = merged_table[duplicate_values]\n",
    "#print(rows_with_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db5d6a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We realised that there are duplicates of features in the dataframe, thus we wil drop the one with a lower rank\n",
    "# Drop duplicates based on the specified column, keeping the first occurrence\n",
    "drop_duplicate = merged_table.drop_duplicates(subset = ['Feature_Names'], keep = 'first')\n",
    "'''This will drop one of the rows that came lower in the DataFrame based on the specified\n",
    "column name and keep only the first occurrence of the duplicate values''';\n",
    "drop_duplicate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a4346",
   "metadata": {},
   "source": [
    "### Our proposed method of determining and selection optimal gene subset based on minimal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3bc33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulate as much as yuh can, both 'n' and size of each n = 1\n",
    "\n",
    "#Activate this set for n = 5 with (100,200,300,400,500)\n",
    "#Now we select top 100 \n",
    "Top_100 = drop_duplicate.head(100)\n",
    "Top_100_features = Top_100['Feature_Names'].tolist()\n",
    "Top_100_data = data2.loc[:,Top_100_features]\n",
    "\n",
    "#Now we select top 200 \n",
    "Top_200 = drop_duplicate.head(200)\n",
    "Top_200_features = Top_200['Feature_Names'].tolist()\n",
    "Top_200_data = data2.loc[:,Top_200_features]\n",
    "\n",
    "#Now we select top 300 \n",
    "Top_300 = drop_duplicate.head(300)\n",
    "Top_300_features = Top_300['Feature_Names'].tolist()\n",
    "Top_300_data = data2.loc[:,Top_300_features]\n",
    "\n",
    "#Now we select top 400 \n",
    "Top_400 = drop_duplicate.head(400)\n",
    "Top_400_features = Top_400['Feature_Names'].tolist()\n",
    "Top_400_data = data2.loc[:,Top_400_features]\n",
    "\n",
    "#Now we select top 500 \n",
    "Top_500 = drop_duplicate.head(500)\n",
    "Top_500_features = Top_500['Feature_Names'].tolist()\n",
    "Top_500_data = data2.loc[:,Top_500_features]\n",
    "\n",
    "\n",
    "\n",
    "'''#Now we select top n \n",
    "Top_n = drop_duplicate.head(n)\n",
    "Top_n_features = Top_n['Feature_Names'].tolist()\n",
    "Top_n_data = data2.loc[:,Top_n_features]''';\n",
    "\n",
    "\n",
    "\n",
    "#Activate this set for n = 10 with (50,100,150,200,250,300,350,400,450,500)\n",
    "#Now we select top 50 \n",
    "'''Top_50 = drop_duplicate.head(10)\n",
    "Top_50_features = Top_50['Feature_Names'].tolist()\n",
    "Top_50_data = data2.loc[:,Top_50_features]\n",
    "\n",
    "#Now we select top 100 \n",
    "Top_100 = drop_duplicate.head(20)\n",
    "Top_100_features = Top_100['Feature_Names'].tolist()\n",
    "Top_100_data = data2.loc[:,Top_100_features]\n",
    "\n",
    "#Now we select top 150 \n",
    "Top_150 = drop_duplicate.head(30)\n",
    "Top_150_features = Top_150['Feature_Names'].tolist()\n",
    "Top_150_data = data2.loc[:,Top_150_features]\n",
    "\n",
    "#Now we select top 200 \n",
    "Top_200 = drop_duplicate.head(40)\n",
    "Top_200_features = Top_200['Feature_Names'].tolist()\n",
    "Top_200_data = data2.loc[:,Top_200_features]\n",
    "\n",
    "#Now we select top 250 \n",
    "Top_250 = drop_duplicate.head(50)\n",
    "Top_250_features = Top_250['Feature_Names'].tolist()\n",
    "Top_250_data = data2.loc[:,Top_250_features]\n",
    "\n",
    "#Now we select top 300 \n",
    "Top_300 = drop_duplicate.head(60)\n",
    "Top_300_features = Top_300['Feature_Names'].tolist()\n",
    "Top_300_data = data2.loc[:,Top_300_features]\n",
    "\n",
    "#Now we select top 350 \n",
    "Top_350 = drop_duplicate.head(70)\n",
    "Top_350_features = Top_350['Feature_Names'].tolist()\n",
    "Top_350_data = data2.loc[:,Top_350_features]\n",
    "\n",
    "#Now we select top 400 \n",
    "Top_400 = drop_duplicate.head(80)\n",
    "Top_400_features = Top_400['Feature_Names'].tolist()\n",
    "Top_400_data = data2.loc[:,Top_400_features]\n",
    "\n",
    "#Now we select top 450 \n",
    "Top_450 = drop_duplicate.head(90)\n",
    "Top_450_features = Top_450['Feature_Names'].tolist()\n",
    "Top_450_data = data2.loc[:,Top_450_features]\n",
    "\n",
    "#Now we select top 500 \n",
    "Top_500 = drop_duplicate.head(100)\n",
    "Top_500_features = Top_500['Feature_Names'].tolist()\n",
    "Top_500_data = data2.loc[:,Top_500_features]''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9107687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_100_data.shape[1] #sample to look at how it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "481a32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.ravel(target) #converting our target variable into a numpy array\n",
    "#target = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "056f1f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rates of the splits [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Index of best split:  0\n",
      "Shape of selected split:  (72, 100)\n",
      "Training set:(65, 100)\n",
      "Testing set:(7, 100)\n",
      "Training_Label set:(65,)\n",
      "Testing_Lable set:(7,)\n"
     ]
    }
   ],
   "source": [
    "#Activate for n = 10\n",
    "#data_sizes = [Top_50_data.values, Top_100_data.values, Top_150_data.values,Top_200_data.values,Top_250_data.values,Top_300_data.values, Top_350_data.values, Top_400_data.values,Top_450_data.values,Top_500_data.values]\n",
    "#Activate for n = 5\n",
    "data_sizes = [Top_100_data.values,Top_200_data.values,Top_300_data.values,Top_400_data.values,Top_500_data.values] \n",
    "best_size = []\n",
    "\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for train_index, test_index in kf.split(data_size):\n",
    "        X_train, X_test = data_size[train_index], data_size[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "        selection_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "        selection_model.fit(X_train, y_train)\n",
    "        y_pred = selection_model.predict(X_test)\n",
    "        error_rate = 1 - (accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    best_size.append(round(error_rate,2))\n",
    "    #print(f'The error rate of {data_size.shape[1]} top features is: {round(error_rate,2)}, while the accuracy id {1- (round(error_rate,2))}%')\n",
    "    #print('\\n')\n",
    "print(\"Error rates of the splits\", best_size)\n",
    "\n",
    "#we auotmatically select the best subset size based on the error rate value and use it in our SSA\n",
    "error_index = best_size.index(min(best_size)) #find the min value in best_size ie.,min error rate = best acccuracy\n",
    "selected_Top_data = data_sizes[error_index] # Access the corresponding element in data_sizes using the index of min value of best_size\n",
    "\n",
    "print('Index of best split: ', error_index) #printing for debugging\n",
    "print('Shape of selected split: ', selected_Top_data.shape) #printing for debugging\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "#Because we are using the same value of k and random state, we will always get same train-test split and hence, same result\n",
    "\n",
    "for train_index, test_index in kf.split(selected_Top_data):\n",
    "    x_train, x_test = selected_Top_data[train_index], selected_Top_data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "fold = {'xt': x_train, 'yt': y_train, 'xv': x_test, 'yv': y_test} #Requirement for our SSA algorithm\n",
    "#We print out to see the number of instances in each of the classes\n",
    "print(f'Training set:{x_train.shape}')\n",
    "print(f'Testing set:{x_test.shape}')\n",
    "print(f'Training_Label set:{y_train.shape}')\n",
    "print(f'Testing_Lable set:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6198202c",
   "metadata": {},
   "source": [
    "### We start defining our SSA funtions from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca8f7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of using the random initialization, we use the chaotic map initialization (sinusoidal map)\n",
    "def sinusoidal_map(P, x0, n):\n",
    "\n",
    "    # Initialize an array to store the generated values\n",
    "    values = np.zeros(n)\n",
    "    # Set the initial value\n",
    "    x = x0\n",
    "    # Generate values using the sinusoidal map equation\n",
    "    #By default, all values are within [0-1]\n",
    "    for i in range(n):\n",
    "        x = P * (x ** 2) * np.sin(np.pi * x)\n",
    "        values[i] = x\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c56f5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''P = 2.3\n",
    "x0 = .7\n",
    "n = 10\n",
    "gen_vals = sinusoidal_map(P, x0, n)\n",
    "assigned_val = np.random.choice(gen_vals)\n",
    "assigned_val '''; #Just testing the workings of the sinusoidal map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a040290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chaotic map (Sinusoidal) population initailization as opposed to random\n",
    "def init_position(lb, ub, N, dim, P, x0):\n",
    "    X = np.zeros([N, dim], dtype='float')\n",
    "    \n",
    "    chaotic_values = sinusoidal_map(P, x0, N * dim)\n",
    "    # Assign the chaotic values to the positions within bounds\n",
    "    index = 0\n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            X[i,d] = lb[0,d] + (ub[0,d] - lb[0,d]) * chaotic_values[index]\n",
    "            index +=1\n",
    "            #X[i,d] = lb[d] + (ub[d] - lb[d]) * np.random.rand()\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9a39e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def binary_conversion(X, thres, N, dim):\n",
    "\n",
    "    Xbin = np.zeros([N, dim], dtype='int')\n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            if sigmoid(X[i, d]) > thres:\n",
    "                Xbin[i, d] = 1\n",
    "            else:\n",
    "                Xbin[i, d] = 0\n",
    "    return Xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccae4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making our search space to remian between 0 and 1\n",
    "def boundary(x, lb, ub):\n",
    "    if x < lb:\n",
    "        x = lb\n",
    "    if x > ub:\n",
    "        x = ub\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0645b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error rate/accuracy\n",
    "def error_rate(xtrain, ytrain, x, opts):\n",
    "    #parameters\n",
    "    k = opts['k']\n",
    "    \n",
    "    fold = opts['fold']\n",
    "    xt = fold['xt']\n",
    "    yt = fold['yt']\n",
    "    xv = fold['xv']\n",
    "    yv = fold['yv']\n",
    "    \n",
    "    #Number of instances\n",
    "    num_train = np.size(xt, 0)\n",
    "    num_valid = np.size(xv, 0)\n",
    "    #Define selected features\n",
    "    xtrain = xt[:, x == 1]\n",
    "    ytrain = yt.reshape(num_train)\n",
    "    xvalid = xv[:, x == 1]\n",
    "    yvalid = yv.reshape(num_valid)\n",
    "    \n",
    "    #training our KNN model\n",
    "    mdl = KNeighborsClassifier(n_neighbors=k)\n",
    "    mdl.fit(xtrain, ytrain)\n",
    "    \n",
    "    #making predictions\n",
    "    ypred = mdl.predict(xvalid)\n",
    "    acc = accuracy_score(ypred, yvalid)\n",
    "    #acc = np.sum(yvalid == ypred) / num_valid\n",
    "    error = 1 - acc\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a369815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error rate and Feature Size (Fitness Fucntion)\n",
    "def Fun(xtrain, ytrain, x, opts):\n",
    "    #parameters\n",
    "    alpha = 0.99 #default value in literature\n",
    "    beta = 1 - alpha #default value in literature\n",
    "    \n",
    "    #original feature size\n",
    "    max_feat = len(x)\n",
    "    #number of selected features\n",
    "    num_feat = np.sum(x==1)\n",
    "    #If no feature is selected smiles (impossible)\n",
    "    if num_feat == 0:\n",
    "        cost = 1 #Add your code if you like\n",
    "    else:\n",
    "        #get error rate fucntion\n",
    "        error = error_rate(xtrain, ytrain, x, opts)\n",
    "        #objective/fitness fucntion\n",
    "        cost = alpha * error + beta * (num_feat/max_feat)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca5986e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fs(xtrain, ytrain, opts):\n",
    "    #our parameters\n",
    "    ub = 1\n",
    "    lb = 0\n",
    "    thres = .5\n",
    "    P = 2.3 #according to literature\n",
    "    x0 = 0.7 #according to literature\n",
    "    \n",
    "    N = opts['N']\n",
    "    max_iter = opts['T']\n",
    "    \n",
    "    #The dimension of our dataset\n",
    "    dim = np.size(xtrain, 1)\n",
    "    if np.size(lb) == 1:\n",
    "        ub = ub * np.ones([1, dim], dtype = 'float')\n",
    "        lb = lb * np.ones([1, dim], dtype = 'float')\n",
    "        \n",
    "    #Initialize position of salps\n",
    "    X = init_position(lb, ub, N, dim, P, x0) #Sinusoidal map\n",
    "    \n",
    "    fit = np.zeros([N, 1], dtype = 'float')\n",
    "    Xf = np.zeros([1, dim], dtype = 'float')\n",
    "    fitF = float('inf')\n",
    "    curve = np.zeros([1, max_iter], dtype = 'float')\n",
    "    t = 0\n",
    "    \n",
    "    while t < max_iter:\n",
    "        #binary conversion\n",
    "        Xbin = binary_conversion(X, thres, N, dim)\n",
    "        \n",
    "        #Fitness\n",
    "        for i in range(N):\n",
    "            fit[i,0] = Fun(xtrain, ytrain, Xbin[i,:], opts)\n",
    "            if fit[i,0] < fitF:\n",
    "                Xf[0,:] = X[i,:]\n",
    "                fitF = fit[i,0]\n",
    "                \n",
    "        #store results\n",
    "        curve[0,t] = fitF.copy()\n",
    "        print('Iteration: ', t + 1)\n",
    "        print(\"Best (SSA): \", curve[0,t])\n",
    "        t = t + 1\n",
    "        \n",
    "        #Compute coefficent, c1 from SSA algorithm\n",
    "        c1 = 2 * np.exp(-(4 * t / max_iter)**2)\n",
    "        \n",
    "        for i in range(N):\n",
    "            #First leader update\n",
    "            if i == 0:\n",
    "                for d in range(dim):\n",
    "                    #coefficient of c2 and c3 in the range of 0 - 1 where random originally but we use chaotic map\n",
    "                    \n",
    "                    c2 = np.random.choice(sinusoidal_map(P, x0, 30))\n",
    "                    c3 = np.random.choice(sinusoidal_map(P, x0, 30))\n",
    "                    #c2 = np.random.rand()\n",
    "                    #c3 = np.random.rand()\n",
    "                    #leader update\n",
    "                    if c3>=.5: #from the literature\n",
    "                        X[i,d] = Xf[0,d] + c1 * ((ub[0,d] -lb[0,d]) * c2 + lb[0,d])\n",
    "                    else:\n",
    "                        X[i,d] = Xf[0,d] - c1 * ((ub[0,d] - lb[0,d]) * c2 + lb[0,d])\n",
    "                        \n",
    "                    #boundary\n",
    "                    X[i,d] = boundary(X[i,d], lb[0,d], ub[0,d])\n",
    "                \n",
    "            #salp update\n",
    "            elif i >= 1:\n",
    "                for d in range(dim):\n",
    "                    #salp update by following leader salp\n",
    "                    X[i,d] =(X[i,d] + X[i - 1, d]) / 2\n",
    "                    #boundary\n",
    "                    X[i,d] = boundary(X[i,d], lb[0,d], ub[0,d])\n",
    "                \n",
    "    \n",
    "    #Best feature subset\n",
    "    Gbin = binary_conversion(Xf, thres, 1, dim)\n",
    "    Gbin = Gbin.reshape(dim)\n",
    "    pos  = np.asarray(range(0,dim))\n",
    "    sel_index = pos[Gbin == 1]\n",
    "    num_feat = len(sel_index)\n",
    "    \n",
    "    #create dictionary\n",
    "    ssa_data = {'sf': sel_index, 'c': curve, 'nf': num_feat}\n",
    "    \n",
    "    return ssa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd0e9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you run our SSA algorithm\n",
    "#Now we set the general parameters\n",
    "K = 5 #K value in KNN\n",
    "N = 30 #Population size/swarm size\n",
    "T = 50 #Max iteration/generations\n",
    "opts = {'k': K, 'fold': fold, 'N': N, 'T': T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eac9c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Best (SSA):  0.010000000000000009\n",
      "Iteration:  2\n",
      "Best (SSA):  0.005900000000000005\n",
      "Iteration:  3\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  4\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  5\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  6\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  7\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  8\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  9\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  10\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  11\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  12\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  13\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  14\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  15\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  16\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  17\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  18\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  19\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  20\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  21\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  22\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  23\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  24\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  25\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  26\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  27\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  28\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  29\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  30\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  31\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  32\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  33\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  34\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  35\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  36\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  37\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  38\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  39\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  40\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  41\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  42\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  43\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  44\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  45\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  46\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  47\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  48\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  49\n",
      "Best (SSA):  0.005100000000000005\n",
      "Iteration:  50\n",
      "Best (SSA):  0.005100000000000005\n"
     ]
    }
   ],
   "source": [
    "#Now we perform our feature selection by calling the main module\n",
    "feature_selection_mdl = main_fs(selected_Top_data, target, opts) #feature selection model\n",
    "sf = feature_selection_mdl['sf'] #index of selected features\n",
    "#print(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b049db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with selected features\n",
    "num_train = np.size(x_train,0)#checks the number of samples slected in the x_train and assign to num_train\n",
    "num_test = np.size(x_test, 0)#checks the number of samples slected in the x_train and assign to num_train\n",
    "xtrain = x_train[:,sf]\n",
    "ytrain = y_train.reshape(num_train)\n",
    "xtest = x_test[:,sf]\n",
    "ytest = y_test.reshape(num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce155687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we build our model i.e., the classifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "KNN_model.fit(xtrain, ytrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a35213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to calculate accuracy for our unseen data\n",
    "def train_test_accuracy(model, xtest, ytest, name = ''):\n",
    "    y_pred = model.predict(xtest)\n",
    "    test_accuracy = round(accuracy_score(y_pred, ytest)*100, 2)\n",
    "    test_F1_measure = round(f1_score(y_pred, ytest)*100,2)\n",
    "    error = 1 - round(accuracy_score(y_pred, ytest), 3)\n",
    "    precision = precision_score(ytest, y_pred)\n",
    "    recall = recall_score(ytest, y_pred)\n",
    "        \n",
    "    return print(\"The ACCURACY SCORE is: {} \\nThe F1_MEASURE is: {} \\nThe error rate is: {} \\nThe precision is: {} \\nThe recall is: {}\". format(test_accuracy, test_F1_measure, error, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e00a73d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ACCURACY SCORE is: 100.0 \n",
      "The F1_MEASURE is: 100.0 \n",
      "The error rate is: 0.0 \n",
      "The precision is: 1.0 \n",
      "The recall is: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Calling our fucntion to display result\n",
    "train_test_accuracy(KNN_model, xtest, ytest, name = 'SSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a515f1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of FEATURES selected is: 51\n"
     ]
    }
   ],
   "source": [
    "#Now we check the number of selected features\n",
    "Number_of_features = len(sf)\n",
    "print(f'The number of FEATURES selected is: {Number_of_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edc15247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_probabilities = KNN_model.predict_proba(xtest)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539d17f",
   "metadata": {},
   "source": [
    "#### End of project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4dfd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
